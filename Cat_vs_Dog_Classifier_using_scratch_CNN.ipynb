{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat_vs_Dog_Classifier_using_scratch_CNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/gauravbansal98/Dog-vs-Cat-Classifier/blob/master/Cat_vs_Dog_Classifier_using_scratch_CNN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MlkJawZMQCzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5sApX-rXRAc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c8f6b9df-3cdd-4e93-dea5-77e0f1ed82ee"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\r\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XjafQ99tRQia",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/Cat vs Dog Classifier\")\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RR9LBsgXYaFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = np.load('train_data.npy')\n",
        "test_data = np.load('test_data.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20WQDDAIpzQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8db0e58a-7e37-4f2d-d463-792d2b79a4da"
      },
      "cell_type": "code",
      "source": [
        "print(np.shape(train_data))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AxLIRBaup-Es",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_data = train_data[:23552]\n",
        "validation_data = train_data[23552:25000]\n",
        "training_x = []\n",
        "training_y = []\n",
        "validation_y = []\n",
        "validation_x = []\n",
        "for i in range(23552):\n",
        "  training_x.append(training_data[i][0])\n",
        "  training_y.append(training_data[i][1])\n",
        "for i in range(1448):\n",
        "  validation_x.append(validation_data[i][0])\n",
        "  validation_y.append(validation_data[i][1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFNbUo8i7xnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content')\n",
        "!git clone https://github.com/mixuala/colab_utils\n",
        "import colab_utils.tboard\n",
        "ROOT = %pwd\n",
        "print(ROOT)\n",
        "LOG_DIR = os.path.join(ROOT, 'gaurav')\n",
        "print(LOG_DIR)\n",
        "colab_utils.tboard.launch_tensorboard( bin_dir=ROOT, log_dir=LOG_DIR )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsRoOq5uqLQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "hm_epochs = 30\n",
        "batch_size = 1024\n",
        "\n",
        "starting_learning_rate = .001\n",
        "\n",
        "mode = tf.placeholder(dtype = tf.bool, name = 'mode')\n",
        "\n",
        "x = tf.placeholder(dtype = tf.float32, shape = [None, 50, 50, 3], name = 'input_labels')\n",
        "y = tf.placeholder(dtype = tf.int32, shape = [None, 2], name = 'output_labels')\n",
        "global_step = tf.Variable(0, trainable = False, name = 'global_step')\n",
        "learning_rate = tf.placeholder('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lqS_GD8_s27u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def CNN_model(x, mode):\n",
        "  with tf.name_scope('CNN_network'):\n",
        "    input_layer = tf.reshape(x, [-1, 50, 50, 3])\n",
        "    \n",
        "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=64, kernel_size=3,strides = 1,\n",
        "                             padding=\"same\", activation=tf.nn.relu)\n",
        "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=2, strides=2, padding = \"same\")\n",
        "    \n",
        "    conv2 = tf.layers.conv2d(inputs=pool1, filters=128, kernel_size=3, strides = 1,\n",
        "                             padding=\"same\", activation=tf.nn.relu)                             \n",
        "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=3, strides=2, padding = \"same\")\n",
        "    \n",
        "    conv3 = tf.layers.conv2d(inputs=pool2, filters=256, kernel_size=3,\n",
        "                             padding=\"same\", activation=tf.nn.relu)\n",
        "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=2, strides=2, padding = \"valid\")\n",
        "    \n",
        "    #pool3_flat = tf.layers.flatten(pool3)\n",
        "    pool3_flat = tf.reshape(pool3, (-1, 6*6*256))\n",
        "    dense1 = tf.layers.dense(inputs=pool3_flat, units=256, activation=tf.nn.relu)\n",
        "    dropout = tf.layers.dropout(inputs=dense1, rate= .2, training=mode)\n",
        "\n",
        "    logits = tf.layers.dense(inputs=dropout, units=2)\n",
        "\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nON9rkOCsz-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rWzzD-EYxEk0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "prediction = CNN_model(x, mode)\n",
        "\n",
        "with tf.name_scope('cost'):\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = prediction, labels = y))\n",
        "summary = tf.summary.scalar('total_cost', cost)\n",
        "#learning_rate = tf.train.exponential_decay(starting_learning_rate, global_step,\n",
        "                                            #450, 0.1, staircase=True)\n",
        "with tf.name_scope('optimizer'):\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost, global_step = global_step)\n",
        "\n",
        "merged = tf.summary.merge_all()\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "train_writer = tf.summary.FileWriter('./gaurav',sess.graph)\n",
        "k = 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsnfU3XhH0n9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "5c80e81f-316b-4330-ac60-d5d650d10794"
      },
      "cell_type": "code",
      "source": [
        "for i in range(hm_epochs):\n",
        "  epoch_loss = 0\n",
        "  starting  = 0\n",
        "  end = batch_size\n",
        "  while end < 23000:\n",
        "    epoch_x = training_x[starting : end]\n",
        "    epoch_y = training_y[starting : end]\n",
        "\n",
        "    o, c, m = sess.run([optimizer, cost, merged], feed_dict = {x : epoch_x, y : epoch_y, mode : True, learning_rate : .001})\n",
        "    epoch_loss += c\n",
        "    train_writer.add_summary(m, k)\n",
        "    k += 1\n",
        "    starting = end\n",
        "    end += batch_size\n",
        "  print('epoch' , i, 'completed out of ', hm_epochs, 'loss ', epoch_loss)\n",
        "saver.save(sess, './model')  \n",
        "\n",
        "\n"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 completed out of  30 loss  808.2898303866386\n",
            "epoch 1 completed out of  30 loss  14.81868326663971\n",
            "epoch 2 completed out of  30 loss  14.36098599433899\n",
            "epoch 3 completed out of  30 loss  13.746380388736725\n",
            "epoch 4 completed out of  30 loss  13.231847822666168\n",
            "epoch 5 completed out of  30 loss  13.013240814208984\n",
            "epoch 6 completed out of  30 loss  12.482291996479034\n",
            "epoch 7 completed out of  30 loss  11.987463057041168\n",
            "epoch 8 completed out of  30 loss  11.757941484451294\n",
            "epoch 9 completed out of  30 loss  11.492822051048279\n",
            "epoch 10 completed out of  30 loss  10.88709381222725\n",
            "epoch 11 completed out of  30 loss  10.3173408806324\n",
            "epoch 12 completed out of  30 loss  9.68705627322197\n",
            "epoch 13 completed out of  30 loss  9.533073246479034\n",
            "epoch 14 completed out of  30 loss  9.274436950683594\n",
            "epoch 15 completed out of  30 loss  9.063064962625504\n",
            "epoch 16 completed out of  30 loss  8.618904829025269\n",
            "epoch 17 completed out of  30 loss  8.554099649190903\n",
            "epoch 18 completed out of  30 loss  8.061651080846786\n",
            "epoch 19 completed out of  30 loss  7.628639221191406\n",
            "epoch 20 completed out of  30 loss  7.148348093032837\n",
            "epoch 21 completed out of  30 loss  6.835569679737091\n",
            "epoch 22 completed out of  30 loss  6.779075562953949\n",
            "epoch 23 completed out of  30 loss  6.605874270200729\n",
            "epoch 24 completed out of  30 loss  6.301611363887787\n",
            "epoch 25 completed out of  30 loss  6.055291876196861\n",
            "epoch 26 completed out of  30 loss  6.048546150326729\n",
            "epoch 27 completed out of  30 loss  6.242107391357422\n",
            "epoch 28 completed out of  30 loss  5.7168596386909485\n",
            "epoch 29 completed out of  30 loss  5.409135639667511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "metadata": {
        "id": "KHedB_aQIs_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "f3ff081e-1fc0-4482-fe64-01ea9a740ecb"
      },
      "cell_type": "code",
      "source": [
        "correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "print('Accuracy:',sess.run(accuracy, feed_dict = {x:validation_x, y:validation_y, mode : False})) "
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7921271\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}